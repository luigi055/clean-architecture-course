#Clean Architecture:

Clean architecture is a set of practices used to create modern software architecture that is simple, understandable, flexible, testable and maintainable.

Clean Architecture is a more modern replacement for the traditional three.

## What software architecture really is?

It's not easy to define. There are a few general concepts that we can probably all agree upon.

1. It's High-Level.
2. It has to do with the **Structure** of software or how things are organized.
3. It typically involves **layers** which are vertical partitions of the system.
4. It typically involves **Components** of some kind, which are typically horizontal partitions within each layer.
5. It involves the relationshops between these things, that is how they're all wired together.

## Levels of architectural Abstraction

When we're discussing architecture we can focus on one of many levels of abstraction. Starting at the top, that is the most abstract representation of software.

At the top we have the **System**, which can be represented as a set of one or more **Subsystems**, which are typically divided into one or more **Layers** which are often subdivided into one or more **Components**, which contain **Classes** that contain **data** and **methods**.

## What is Bad Architecture?

- It's complex, but due to accidental complexity rather that necessary complexity.
- It's incoherent in the sense that the parts don't seem like they fit together.
- It's rigid, that is the architecture resists change or makes it difficult to evolve the architecture over time.
- It's brittle, touching a part of the code over here might break another part of the code somewhere else.
- It's untestable, that is,you'd really like to write unit tests and integration tests, but the architecture fights you eaxch step of the the way.
- ultimately all of these lead to an architecture that's unmaintainable over the life of the project.

## What is a Good Architecture?

- It's simple or at least it's only as complex as is necessary, and that complexity is not accidental.
- It's understandable, that is, it's easy to reason about the software as a whole.
- It's flexible, we can easily adapt the system to meet changing requirements.
- It's emergent, the architecture evolves over the life of the project.
- It's testable, the architecture makes testing easier, not harder.
- And ultimately all of this leads to an architecture that's more maintainable over the life of the project.

The way we could sum up clean architecture is that it's architecture that is designed for the inhabitants of the architecture... Not for the architect... or the machine.

Clean architecture is a philosophy of architectural essentialism. It's about focusing on what is truly essential to the software's architecture versus what is just implementation detail.

By desiging for the inhabitants we mean the people that will be living within the architecture during the life of the project. This means the users of the system, the developers building the system and the developers maintaining the system.

By not designing for the architect, we mean that the architect should put aside his of her own desires, preferences and wishes, and only consider what is best for the inhabitants of the architecture with each decision that is made.

By not designing for the machine we mean that we should optimize the architecture first for the needs of the inhabitants, that is the users and the developers, and only optimize for the machine when the cost of performance issues to the users, who are inhabitants of the architecture, outweights the benefit of a clean design to the developers who are also inhabitants of the architecture.

Essentially,we want to avoid premature optimization, which as visionary computer scientists Donald Knuth says, is the root of all evil in software development.

## Why invest in Clean Architecture?

- Cost/Benefits.
- Minimize Cost.
- Maximize Value.
- Maximize ROI.

Clean Architecture attemps to do this in several ways.

- First, clean architecture focuses on the essential needs of the primary inhabitants of the system; that are the users. We attempt to build a system that mirrors the use cases and mental models of the users by embedding these use cases and mental models in both our architecture and our code

- Second, clean architecture builds only what is necessary when it is necessary. We attempts to create only the features and corresponding architecture that are necessary to solve the immediate needs of the users in order of each features perceived business value. We attemp to do this without creating any accidental complexity, unnecessary features, premature performance optimizations or architectural embellishments. This helpsto reduce the cost of creating the system.

- Third, clean architecture optimizes for maintainability. For an average enterprise application with a sufficiently long lifecycle, way 10 years or so, we spend significantly more time and money maintaining the system than we do creating it. Several sources that I've seen indicate that roughly 60 to 80% of the cost of the life of the software application comes from maintenance. We optimize for maintainability, which clean architecture does, we in theory reduce the cost of maintaining the system.

In clean Architecture the **Context** is king.
**All decisions are a tradeoff.**
**Align with bussiness goals.**
**Use your best judgement**

# Domain-Centric Architecture.

Here we have the classic three-layer database-centric architecture. Its key feature is that the user interface, business logic, and data access layer revolve around the database. The database is essential, and thus, it's at the center of this architecture. However, a new perspective has changed the way many of us look at our architecture. Rather than having the database at the center of our architecture, some of us are putting the domain at the center, and making the database just an implementation detail outside of the architecture.

Here the domain is essential, and the database is just a detail. So why has this happened? I think this change in perspective is best summed up by a quote from Robert C. Martin, better known in the software industry as Uncle Bob. He says, "the first concern of the architect is to make sure that the house is usable, it is not to ensure that the house is made of brick. " This change in architectural perspective is being caused by a change in perspective about what is essential in an architecture versus what is just an implementation detail. Using our building architecture metaphor, when we're building a house what is essential versus what is a detail?

- The space inside of a house is essential. Without empty space to inhabit the house would serve no purpose.
- The usability of the house is essential. If the house didn't contain rooms and features to support our primary needs, again, the house would not serve its purpose.
- However, the building material is just an implementation detail. We could build it out of brick, stone, wood or many other materials.
- In addition, the ornamentation is just a detail. We could still live in this house whether it had Victorian molding, gold trim, French doors or no ornamentation at all.

The things that are essential in a house are so because they support the primary needs of the inhabitants of the house. Everything else is just an implementation detail. In clean architecture the same holds true. What is essential are the things that support the primary needs of the inhabitants of the architecture.

- The domain model is essential. Without it the system would not represent the mental models of the users.
- The use cases are essential. Without them the system would not solve the user's problems.
- However, the presentation is just a detail. We can deliver the UI in web forms, ASP. NET MVC or as a single page JavaScript application.
- The persistence is just a detail. We can store the data in a relational database, no a SQL database, or as plain old JSON files.

Now don't get me wrong, the presentation and persistence technologies are very important. They are just not essential to solving the problem that the user is attempting to solve with the application. Once we've changed our perspective about what is essential versus what is a detail in software architecture, we can start to see why a transition from database-centric architecture to domain-centric architecture is occurring. With database-centric architectures the database is essential, so the database is at the center of the application, and all dependencies point towards the database. With domain-centric architectures the domain and use cases are essential, and the presentation and persistence are just a detail, so the domain is at the center of the application wrapped in an application layer and all dependencies point towards the domain. So now let's take a look at a few types of domain-centric architectures.

1.  First, we have Alistair Cockburn's hexagonal architecture. It's a layered architecture with the application layer, and thus transitively, the domain at the center of the architecture. In addition, it's a plugin architecture which includes ports and adapters. Essentially, the outer layers of the architecture are adapting the inner application layer to the various presentation mediums, persistence mediums, and external systems. You can run, and thus test, an isolation in this entire application architecture without a UI, a database or any external dependencies.

2.  Next, with the onion architecture by Jeffrey Palermo. This is also a layered architecture with the domain at the center surrounded by an application layer. The outer layers consist of a thin UI as a presentation layer, and an infrastructure layer, which includes persistence. In addition, all dependencies point towards the center of the architecture, that is no inner layer knows about any outer layer. Once again, you can test this application architecture in isolation without a UI, a database or any external dependencies.
3.  Finally, we have the clean architecture by Uncle Bob. Once again, it's a layered architecture with the domain, that is the entities, at the center surrounded by an application layer, that is the use cases. The outer layer consists of ports and adapters adapting the application core to the external dependencies via controllers, gateways, and presenters. In addition, Uncle Bob goes one step further by incorporating Ivar Jacobson's BCE architecture pattern to explain how the presentation layer and the application layer should be wired up.

All three of these architectures have roughly the same benefits. However, as Mark Seaman has pointed out, all of these domain-centric architectures are essentially just focusing on different aspects of the same key set of ideas. Essentially, the all put the domain model at the center, wrap it in an application layer, which embeds the use cases, adapts the application to the implementation details, and all dependencies should point inwards towards the domain. So why would we want to use a domain-centric architecture?

1.  First, focus is placed on the domain, which is essential to the inhabitants of the architecture, that is the users and the developers which, as we've learned in the previous module, provides several benefits and cost reductions for our software.
2.  Second, there is less coupling between the domain logic and the implementation details, for example, the presentation, database, and operating system. This allows the system to be more flexible and adaptable, and we can much more easily evolve the architecture over time.
3.  Third, using a domain-centric architecture allows us to incorporate Domain Driven Design, which is a great set of strategies by Eric Evans for handling business domains with a high degree of complexity.

So why would we not want to use a domain-centric architecture?

1. First, change is difficult. Most developers come out of college having only been taught the traditional three layer database-centric architecture. In addition, it may also be the only architectural model that the architect knows well enough to offer guidance on.
2. Second, it requires more thought to implement a domain-centric design. You need to know what classes belong in the domain layer, and what classes belong in the application layer rather than just throwing everything in a business logic layer.
3. Third, it has a higher initial cost to implement this architecture compared to a traditional three layer database-centric architecture. However, it typically pays itself off if the application is complex enough, and has a long enough life cycle, which is the case with most modern applications these days.

# Application Layer:

## What is a Layer?

Layers are boundaries or vertical partitions of an application designed to represent different levels of abstraction, maintain the single responsibility principle, isolate developer roles and skills, help support multiple implementations, and assist with varying rates of change. Essentially, layers are the way that we slice an application into manageable units of complexity.

## How analyse the layers of a system

Let's start with what we already know. The classic three-layer database-centric architecture. First, we have our user interface layer, which provides the user with an interface into the application. Next, we have our business layer, which contains the business logic of the application. Finally, we have our data access layer, which contains the logic to read and write to the database. This works just fine for simple CRUD applications, that is applications that perform basic Create, Read, Update, and Delete operations on data within the database; however, it doesn't work all that well with complex or rich domain models. In addition, there's a lot of ambiguity about where application level abstractions versus domain level abstractions should go. This has led to the development of a more modern four-layer domain-centric architecture. First, we have our presentation layer, which provides the user with an interface into the application. Second, we have an application layer, which embeds the use cases of the application as executable code and abstractions. Third, we have a domain layer, which contains only the domain logic of the application. Fourth, we have the infrastructure layer. Oftentimes it makes sense to divide this layer into one or more projects. For example, a common variation is to create a separate project for persistence, and a separate project for the remaining infrastructure. For example, in this diagram we have the persistence portion of the infrastructure layer, which provides the application with an interface to the database or other persistent storage. Then, we have the rest of the infrastructure layer, which provides the application with an interface to the operating system and other third party components. Finally, we have our cross-cutting concerns, which are aspects of the application that cross all the layers of the system. There are obviously a few variations on this architecture. For example, multiple user interfaces, adding a web service layer, separate projects for external dependencies, but the general structure is essentially the same.

## Application Layer:

Here we have the application layer. It implements use cases as executable code, for example, a customer searches for a product, adds it to their cart, and pays with a credit card. We structure this executable use case code as high-level representations of application logic. For example, we might have a query that searches for our product for our customer or a command that adds a product to their shopping cart. The application layer knows about the domain layer, that is, it has a dependency on the domain, but it does not know about the presentation, persistence or infrastructure layers. That is, there are no dependencies on the outer layers of the application. The application layer, however, does contain interfaces for its dependencies that these respective outer layers then implement. Then we use an IoC framework, that is an Inversion of Control framework, and dependency injection to wire up all the interfaces and their implementations at run time.

## Layer Dependencies:

In addition to the dependency arrows in our diagram in orange I've also added additional arrows in blue to indicate the flow of control through the application. We can follow the flow of control through the application from the users at the top of the diagram down to the database and operating system at the bottom of the diagram. In addition, we can follow the dependency arrows, which flow both upwards and downwards towards the domain. Now some of you may be wondering if I've accidentally drawn two of these orange dependency arrows in this diagram upside down, specifically, the arrow between the persistence project and the application project, and the arrow between the infrastructure project and the application project. Now this is a completely reasonable assumption because it's probably quite different than what you've seen with the classic three layer architecture. However, these inverted dependencies are in fact correct. When building this more modern architecture we utilize the dependency inversion principle. It states that abstraction should not depend on details, rather, details should depend on abstractions. So in the persistence and infrastructure layers we implement the inversion of control patter. That is, our dependencies oppose the flow of control in our application. This provides several benefits, such as providing independent deployability. That is, we can replace an implementation in production without affecting the abstraction that it depends upon. It also makes architecture more flexible and maintainable as well. For example, we can swap out our persistence medium and infrastructure dependencies without having negative side effects ripple throughout both the application and domain layers. This is highly useful for agile applications where we often defer implementation decisions as late as possible when we have a much better understanding of the specific needs of our application and its implementations. This is a strategy referred to in Agile software development as the last responsible moment, an idea which we'll talk more about in the last module of this course. Please also note that sometimes we need to add an additional dependency from the persistence project directly to the domain project when using an Object Relational Mapper, that is an ORM. This is the dashed orange arrow in the diagram on the right. This is necessary for the ORM to map domain entities to tables in the database since the persistence layer needs to know about the entities contained in the domain layer. Using an ORM is optional when creating clean architecture, but it can save a tremendous amount of development, time, and effort if used correctly. Here's a quick visual example to show how all of these classes and interfaces are all wired together in our demo application. We have our presentation project, application project, domain project, persistence project, infrastructure project, and our cross-cutting concerns project. In the presentation project we have a SalesController that has a dependency on the ICreateSalesCommand interface in the application project. The CreateSaleCommand class in the application project implements this interface. This class contains the high level application logic that fulfills the use case for creating a new sale. The class has a dependency on the IDatabaseService interface and the IInventoryService interface, both of which are contained in the application project as well. The DatabaseService class in the persistence project implements the IDatabaseService interface, and the InventoryService class in the infrastructure project implements the IInventoryService interface. As we can see, all of the dependencies point towards the application, and thus transitively towards the domain. All of the details, that is implementations, depend upon abstractions, which are interfaces, and we utilize in version of control for both the persistence projects dependency on the on the application project, and the infrastructure project's dependency on the application project as well. Our cross-cutting concerns are a bit different, as there are typically multiple projects that all have dependencies upon them. For our cross-cutting concerns we store both the interfaces and the implementations in the cross-cutting concerns project. For example, the IDateService interface and the DateService class, which implements this interface, are both contained in the cross-cutting concerns project. This is because multiple projects need to reference the IDateService interface, so it must be contained in the cross-cutting concerns project referenced by all of the other projects. So why would we want to implement an application layer in our architecture? First, with an application layer we're placing focus on the use cases of the system, which, as we've stated before, are essential to the primary inhabitants of the architecture, that is the users. This provides us with the same benefits that we discussed in the first module of this course. Second, we embed our use cases as high level, executable code, which then delegate low level steps to other classes. This makes it very easy to understand the code, the use cases intention, and to reason about the software as a whole. This is highly beneficial for developers creating the application, and the developers maintaining the application. Third, it follows the Dependency Inversion Principle, which, as we explained earlier, makes our code more flexible and maintainable. In addition, it allows us to defer implementation decisions until later in the project, and thus evolve the architecture over time. There are also several reasons why we might not want to implement an application layer. First, the primary reason is that there's an additional cost to creating and maintaining this layer. Layers in software architecture are expensive to create and maintain, so we generally want to keep the number of layers in our system as small as possible. Second, we need to spend extra time thinking about what belongs in the application layer, versus what belongs in the domain layer, rather than just throwing it all in a business logic layer. Third, the inversion of control between the application layer and the infrastructure layer is often counterintuitive for novice developers. However, after you've wrapped your brain around it, it becomes quite a bit easier to reason about. So now let's take a look at how the application layer is implemented in our clean architecture demo.

# Commands and Queries:

Back in 1988 Bertrand Meyer taught us that there were two kinds of methods in object oriented software. First, we have a command. A command does something, which means that it should modify the state of the system, but it should not return a value. Next, we have queries. A query answers a question, which means that it should not modify the state of the system, and it should return a value. Bertrand taught us that we should attempt to maintain command query separation where possible. There are many reasons why this is a good idea. For example, to avoid nasty side effects that hide in methods that violate this principle.

## Command-Queries separation exception:

As Martin Fowler points out, this is not always possible. For example, if you have a stack, and you want to pop the first item on the stack, the pop method removes the top item from the stack, which is a command, and returns that top item, which is a query. In addition, if you want to create a new database record you create the database record, which is a command, but you might also need to return the newly created ID, which is a query, so there are clearly exceptions to this rule, but in general we should strive to maintain command query separation where possible.

## Command Query Responsability Separation (CQRS):

Command Query Responsibility Separation architectures or CQRS architectures expand this concept of command query separation to the architectural level. In general, we're dividing the architecture into a command stack, and a query stack, starting at the application layer. This is done for various reasons. The primary reason is that queries should be optimized for reading data, whereas commands should be optimized for writing data. Commands execute behaviors in the domain model, mutate state, raise events, and write to the database. Queries use whatever means is most suitable to retrieve data from the database, project it into a format for presentation, and display it to the user. This change increases both the performance of the commands and queries, but equally important, it increases the clarity of the respective code. CQRS is domain-centric architecture done in a smart way. It knows when to talk to the domain via commands, and when to talk directly to the database via queries. There are three main types of CQRS, which we'll take a look at next.

### Single-database CQRS

The first type of CQRS, we'll call it single-database CQRS for lack of an existing standardized name. This type of CQRS has a single database that is either a third normal form relational database or some type of NoSQL database. Commands execute behavior in the domain, which modify a state, which is then saved to the database through the persistence layer, which is often an ORM, that is an Object Relational Mapper like in Hibernate or Entity Framework. Queries are executed directly against the database using a thin data access layer, which his either an ORM using projections, LINQ to SQL, SQL scripts or stored procedures. This single database CQRS is the simplest of the three types of CQRS architectures.

### Two-database CQRS

The second type of CQRS architecture we'll call Two-database CQRS. This type of CQRS has both a read database and a write database. The command stack has its own database optimized for write operations. For example, a third normal form relational database or a NoSQL database. The query stack, however, uses a database optimized for read operations. For example, a first Normal Form relational database or some other denormalized read optimize data store. The modifications to the right database are pushed into the read database either as a single coordinated transaction across both databases or using an eventual consistency pattern. That is, the two databases may be out of sync temporarily, but will always eventually become in sync, typically on the order of milliseconds. This type of CQRS is more complex than the first, but can afford orders of magnitude improvements in performance on the read side of the system. This makes quite a bit of sense because we generally spend orders of magnitude more time reading from a database than we do writing to it.

### Event sourcing

The third type of CQRS system is typically referred to as event sourcing. The main difference here is that we do not store the current state of our entities in a normalized data store. Instead, we store just the state modifications to the entities over time, represented as events that have occurred to the entities. We store this historical record of all events in a persistence medium called an event store. When we need to use an entity in its current state we replay the events that have occurred to that entity, and we end up with the current state of the entity. Then, once we've reconstructed the current state of the entity we execute our domain logic, and modify the state of the entities accordingly. This new event will then be stored in our event store, so that it can be replayed as needed. Finally, we push the current state of our entity out to the read database, so our read queries will still be extremely fast. This is the most complex of the three types of CQRS, but it has some very powerful benefits in exchange for the additional costs. First, since the current state of each entity can only be derived by replaying the sequence of events that have occurred to that entity, the event store acts as a complete and guaranteed to be true audit trail for the entire system. This is highly valuable in heavily regulated industries where this type of auditability is necessary. Second, we can reconstruct the state of an entire entity at any point in time. This is useful for determining what the state of an entity was at any previous point in time in the system, and this is also very useful for debugging. Third, we can replay events to observe what happened in the system. This is very useful for diagnostics and debugging. In addition, this is also very useful for load testing and regression testing in a test environment using existing production events that have occurred in the system. Fourth, we can project the current state of our entities into more than one type of read optimized datastore. For example, we can simultaneously populate and then query fast text indexing services like Lucene, graph databases, OLAP cubes, In-memory databases, and more. This means that each query can request data from the datastore optimized for querying and presenting the corresponding data. Finally, we can rebuild our production database just by playing the events. All we need to do to get the current state of our system is replay all of the events that have occurred in the past, and we end up with the current state of the system. These are some very powerful features if your architecture needs them; however, it can also be a significant additional expense if you don't actually need any of these features. In addition, despite the fact that most people new to event sourcing assume that the right side of the system will be slow, in reality these systems are actually much faster than you would imagine.
There are also several types of optimizations that can be added, like generating periodic snapshots, if the performance of the right side of the system becomes an issue.

## why would we want to use a CQRS architecture?

First, if you're implementing domain-centric design, implementing CQRS is more efficient from a coding perspective. Commands are coded to use the rich domain models to modify state, and queries are coded directly against the database to read data. Second, by using CQRS we're optimizing the performance of both the query side and the command side for their respective purposes. Depending upon which type of CQRS we implement, this can mean orders of magnitude improvements and performance. Third, by using event sourcing we gain all of the benefits we discussed previously, and a few more that were not discussed. As systems become more complex or require high degrees of auditability these features can become highly valuable to both the business and to the developers. So why would we not want to use CQRS? First, there's an intentional inconsistency in the design of the command stack versus the query stack. Inconsistency in general makes software more complex and difficult to reason about; however, we gain consistency within each stack as a tradeoff. Second, with two-database CQRS, having both a read and write database is more complex, and potentially introduces an eventual consistency model to your databases. Third, event sourcing entails higher cost to create and maintain the event sourcing features. If you'll not be deriving sufficient business value from these additional features event sourcing might not pay for itself in the long run. So now let's take a look at the query side of our demo application.

# Functional Organization:

"The architecture should scream the intent of the system" - Uncle Bob.

The screaming architecture practice is based on the idea that your software's architecture should scream the intent of the system, hence the name screaming architecture. We do this by organizing our architecture around the use cases of the system. Use cases are representations of a user's interaction with the system. For example, interactions like getting a list of all customers, purchasing a product or paying a vendor. The screaming architecture practice is best explained using a metaphor about the architecture of buildings. Let's take a look at this blueprint. We have some bedrooms, a dining room, a living room, kitchen, and a bathroom. It's pretty easy for us to determine the intent of this architecture by quickly scanning across the blueprint. This is clearly the blueprint for a residential building of some kind, and the intent of this architecture is to facilitate a residential living environment. The rooms of this building embody the use cases of the building. We sleep in a bedroom, we cook in a kitchen, we eat in a dining room, and so on. Simply by looking at the rooms contained in an architectural blueprint, which represent the use cases of the building, we can quickly determine the function and intent of the architecture of the building. Now rather than looking at the blueprints for a building let's take a look at the bill of materials for a building instead. We can see that we have some appliances, cabinets, doors, fixtures, and more, but it's very difficult to determine the intent of this architecture. By looking at a list of components used to create the building, rather than the rooms that support the building's use cases, it's much more difficult to determine the function or intent of the architecture of a building. The relationship between the organization of software architecture and the ease of discovering the intent of the architecture is governed by similar principles. We can organize our application's folder structure and namespaces according to the components that are used to build the software, components like models, views, and controllers or we can organize our folder structure and namespaces according to the use cases of the system, concepts that pertain to user's interactions with objects in the system like customers, products, and vendors. For example, let's take a look at two representations of the same software architecture. On the left we have the typical MVC folder structure. Things we all recognize as MVC components, like models, views, and controllers. On the right, however, we have the same web application organized by its high-level use cases like customers, products, and vendors. It's very difficult to determine the intent of the software on the left, but it's much easier to determine the intent of the software on the right. This might sound like an arbitrary decision, whether to organize first by components or by use cases, but there are some definite pros and cons to both of these equally reasonable ways to organize our software. The primary advantage is the functional cohesion; that is, organizing by use cases is generally more efficient than categorical cohesion; that is, organizing by component types because it better models the way we maintain, navigate, and reason about software. Essentially, categorical cohesion is like storing your silverware forks next to your pitch forks and tuning fork just because they're all three forks of some kind, whereas functional cohesion is like storing your forks next to your knives and spoons because we use all three utensils when we're eating. In fact, we can extend the idea of using blueprints for our building architecture metaphor to both visualize and conceptualize our application architecture. Here we have a tree map of the application layer of our demo application. A tree map is a data visualization that allows us to visualize hierarchical data, like the hierarchical relationship between the classes, folders, and namespaces in our demo application. The main rectangle on the screen represents the application project in our overall solution. Each of the large, colored rectangles represents the first folder level within the application project; that is, the aggregate root entity folders. The smaller rectangles represent the individual classes and interfaces contained in those aggregate root folders. The size of each rectangle corresponds to the size of the respective class or interface file that it represents. The colors correspond to each aggregate root entity folder that the classes and interfaces are contained within. As we can see by looking at the blueprint of our code, it is very easy to determine what the function and intent of this application is. In addition, it's easy to see that the items that are used together are grouped together via functional cohesion. This is a principle referred to as special locality; that is, it is often more efficient to keep items that are used together near one another in physical space. In terms of our software project, this means keeping items that are used together near one another in the folder structure of our file system. In fact, we can extend this metaphor one step further and imagine that our code is a multi-story building with each floor representing a layer of the architecture. On the ground floor we have our infrastructure layer, which contains both persistence and the remaining infrastructure classes. On the second floor we have our domain layer, which contains our domain entities. On the third floor we have our application layer, which contains our use cases, and on the top floor we have our presentation layer, which contains our user interface. When we conceptualize and visualize our software this way it becomes pretty apparent to us what the organization of a clean architecture looks like, versus what a messy architecture looks like. Simply by imagining having to live and work inside of this hypothetical building made of code we can get an intuition for whether the organization of our architecture is inhabitable or not.

## Why would we want to use functional organization.

So why would we want to use functional organization in our architecture? First, when we organize by function we utilize the principle of spatial locality; that is, items that are used together live together, just like our forks, knives, and spoons. Second, it's much easier to find things and navigate the folder structure. If we want to work with the employee objects, like the employee models, views, and controllers we just navigate to the employees folder in the presentation layer, and they're all contained in that folder. Third, it helps us to avoid vendor and framework lock in because we're not forced into the folder structure that the vendor insists that we use to implement their framework.

## Why would we not want to use functional organization.

So why would we not want to use functional organization in our architecture? First, we lose the ability to use the default conventions of our frameworks, so we typically have to tell the framework where things are located. Second, we often lose the automatic scaffolding features of our frameworks because they are typically designed to create automatically generated template files by categorical cohesion, since it's easier for the frameworks. Third, categorical cohesion is easier during the creation process; that is, figuring out where something should go when you created it, however, it makes things more difficult over the rest of the life of the project, so you'll typically end up paying more over the life of the project, especially if the project is complex and has long lifecycle. So now let's see how we've used functional organization to organize the classes, folders, and namespaces of our demo application.
